### 机器学习简介 ###

- 机器学习应用领域

<table><tr><td>&emsp;&emsp;机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人等领域。</table></tr></td>

![](https://i.imgur.com/NMWaXEz.png)

- 机器学习算法分类

![](https://i.imgur.com/l77Mrlq.jpg)

1.Group by Learn Style

- 监督学习

![](https://i.imgur.com/kbfgESu.jpg)

<table><tr><td>
&emsp;&emsp;基本上，在监督机器学习中，输入数据被称为训练数据，并且具有已知的标签或结果，例如垃圾邮件/非垃圾邮件或股票价格。在此，通过训练过程中准备模型。此外，还需要做出预测。并且在这些预测错误时予以纠正。训练过程一直持续到模型达到所需水平。

示例问题：分类和回归。
示例算法：逻辑回归和反向传播神经网络。
</table></tr></td>

示例问题：分类和回归。
示例算法：逻辑回归和反向传播神经网络。

- 无监督学习

![](https://i.imgur.com/z94FZPJ.jpg)

在无监督机器学习中，输入数据未标记且没有已知结果。我们必须通过推导输入数据中存在的结构来准备模型。这可能是提取一般规则，但是我们可以通过数学过程来减少冗余。

示例问题：聚类，降维和关联规则学习。
示例算法：Apriori算法和k-Means。

- 半监督学习

![](https://i.imgur.com/M3p4g9H.jpg)

输入数据是标记和未标记示例的混合。存在期望的预测问题，但该模型必须学习组织数据以及进行预测的结构。

示例问题：分类和回归。
示例算法：其他灵活方法的扩展。

2.Group by Similarity

- 回归算法
- 基于实例的算法
- 正则化算法
- 决策树算法
- 贝叶斯算法
- 聚类算法
- 关联规则算法
- 降维算法
- 人工神经网络算法
- 深度学习算法

### 建模与问题解决流程 ###

1. 数据预处理
2. 特征工程
3. 模型选择与评估
4. 寻找最佳超参数：交叉验证
5. 模型分析与模型融合


### 机器学习常用工具 ###

----------

### 数据预处理 ###

### 常用机器学习算法 ###

- 朴素贝叶斯分类器

通常，网页、文档和电子邮件进行分类将是困难且不可能的。这就是朴素贝叶斯分类器机器学习算法的用武之地。分类器其实是一个分配总体元素值的函数。例如，垃圾邮件过滤是朴素贝叶斯算法的一种流行应用。因此，垃圾邮件过滤器是一种分类器，可为所有电子邮件分配标签“垃圾邮件”或“非垃圾邮件”。基本上，它是按照相似性分组的最流行的学习方法之一。这适用于流行的贝叶斯概率定理。

- K-means：聚类算法

通常，K-means是用于聚类分析的无监督机器学习算法。此外，K-Means是一种非确定性和迭代方法，该算法通过预定数量的簇k对给定数据集进行操作。因此，K-Means算法的输出是具有在簇之间分离的输入数据的k个簇。

- 支持向量机

基本上，它是用于分类或回归问题的监督机器学习算法。SVM从数据集学习，这样SVM就可以对任何新数据进行分类。此外，它的工作原理是通过查找将数据分类到不同的类中。我们用它来将训练数据集分成几类。而且，有许多这样的线性超平面，SVM试图最大化各种类之间的距离，这被称为边际最大化。

线性SVM：在线性SVM中，训练数据必须通过超平面分离分类器。
非线性SVM：在非线性SVM中，不可能使用超平面分离训练数据。

- Apriori算法

这是一种无监督的机器学习算法。我们用来从给定的数据集生成关联规则。关联规则意味着如果发生项目A，则项目B也以一定概率发生，生成的大多数关联规则都是IF_THEN格式。例如，如果人们购买iPad，那么他们也会购买iPad保护套来保护它。Apriori机器学习算法工作的基本原理：如果项目集频繁出现，则项目集的所有子集也经常出现。

- 线性回归

它显示了2个变量之间的关系，它显示了一个变量的变化如何影响另一个变量。

- 决策树

决策树是图形表示，它利用分支方法来举例说明决策的所有可能结果。在决策树中，内部节点表示对属性的测试。因为树的每个分支代表测试的结果，并且叶节点表示特定的类标签，即在计算所有属性后做出的决定。此外，我们必须通过从根节点到叶节点的路径来表示分类。

- 随机森林

它是首选的机器学习算法。我们使用套袋方法创建一堆具有随机数据子集的决策树。我们必须在数据集的随机样本上多次训练模型，因为我们需要从随机森林算法中获得良好的预测性能。此外，在这种集成学习方法中，我们必须组合所有决策树的输出，做出最后的预测。此外，我们通过轮询每个决策树的结果来推导出最终预测。

- Logistic回归

这个算法的名称可能有点令人困惑，Logistic回归算法用于分类任务而不是回归问题。此外，这里的名称“回归”意味着线性模型适合于特征空间。该算法将逻辑函数应用于特征的线性组合，这需要预测分类因变量的结果。


 
